{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bae04436",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ff9ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment setup\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import yaml\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up paths\n",
    "current_dir = Path().absolute()\n",
    "project_root = current_dir.parent if current_dir.name == 'notebooks' else current_dir\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"GPU available: {torch.cuda.is_available()}\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef29d69",
   "metadata": {},
   "source": [
    "## 2. Fine-tuning Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03249a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tuning strategy selector\n",
    "FINE_TUNING_STRATEGY = \"conservative\"  # Options: conservative, layerwise, progressive, augmented, regularization, architecture\n",
    "\n",
    "# Base configuration\n",
    "FINE_TUNING_CONFIG = {\n",
    "    \"conservative\": {\n",
    "        \"name\": \"Conservative Fine-tuning\",\n",
    "        \"description\": \"Lower learning rates, maintain model stability\",\n",
    "        \"learning_rate\": 1e-6,\n",
    "        \"vision_lr_factor\": 0.1,\n",
    "        \"epochs\": 5,\n",
    "        \"batch_size\": 12,\n",
    "        \"weight_decay\": 1e-4,\n",
    "        \"label_smoothing\": 0.05,\n",
    "        \"dropout_factor\": 1.0,\n",
    "        \"freeze_layers\": [],\n",
    "        \"augmentation_strength\": \"light\"\n",
    "    },\n",
    "    \"layerwise\": {\n",
    "        \"name\": \"Layer-wise Fine-tuning\",\n",
    "        \"description\": \"Different learning rates for vision, text, and fusion components\",\n",
    "        \"learning_rate\": 5e-6,\n",
    "        \"vision_lr_factor\": 0.05,\n",
    "        \"text_lr_factor\": 0.3,\n",
    "        \"fusion_lr_factor\": 1.0,\n",
    "        \"epochs\": 8,\n",
    "        \"batch_size\": 10,\n",
    "        \"weight_decay\": 5e-4,\n",
    "        \"label_smoothing\": 0.1,\n",
    "        \"dropout_factor\": 1.0,\n",
    "        \"freeze_layers\": [],\n",
    "        \"augmentation_strength\": \"medium\"\n",
    "    },\n",
    "    \"progressive\": {\n",
    "        \"name\": \"Progressive Unfreezing\",\n",
    "        \"description\": \"Gradually unfreeze layers during training\",\n",
    "        \"learning_rate\": 3e-6,\n",
    "        \"vision_lr_factor\": 0.1,\n",
    "        \"epochs\": 12,\n",
    "        \"batch_size\": 12,\n",
    "        \"weight_decay\": 1e-4,\n",
    "        \"label_smoothing\": 0.1,\n",
    "        \"dropout_factor\": 1.0,\n",
    "        \"freeze_schedule\": {1: [\"vision_encoder.layer4\"], 3: [\"vision_encoder.layer3\"], 5: []},\n",
    "        \"augmentation_strength\": \"medium\"\n",
    "    },\n",
    "    \"augmented\": {\n",
    "        \"name\": \"Data Augmentation Enhanced\",\n",
    "        \"description\": \"Strong data augmentation for better generalization\",\n",
    "        \"learning_rate\": 2e-6,\n",
    "        \"vision_lr_factor\": 0.1,\n",
    "        \"epochs\": 10,\n",
    "        \"batch_size\": 10,\n",
    "        \"weight_decay\": 1e-3,\n",
    "        \"label_smoothing\": 0.15,\n",
    "        \"dropout_factor\": 1.0,\n",
    "        \"freeze_layers\": [],\n",
    "        \"augmentation_strength\": \"strong\"\n",
    "    },\n",
    "    \"regularization\": {\n",
    "        \"name\": \"Regularization Tuning\",\n",
    "        \"description\": \"Optimize regularization parameters\",\n",
    "        \"learning_rate\": 3e-6,\n",
    "        \"vision_lr_factor\": 0.1,\n",
    "        \"epochs\": 8,\n",
    "        \"batch_size\": 12,\n",
    "        \"weight_decay\": 2e-3,\n",
    "        \"label_smoothing\": 0.2,\n",
    "        \"dropout_factor\": 1.2,\n",
    "        \"freeze_layers\": [],\n",
    "        \"augmentation_strength\": \"medium\"\n",
    "    },\n",
    "    \"architecture\": {\n",
    "        \"name\": \"Architecture Tweaking\",\n",
    "        \"description\": \"Minor architectural modifications\",\n",
    "        \"learning_rate\": 5e-6,\n",
    "        \"vision_lr_factor\": 0.1,\n",
    "        \"epochs\": 10,\n",
    "        \"batch_size\": 10,\n",
    "        \"weight_decay\": 1e-4,\n",
    "        \"label_smoothing\": 0.1,\n",
    "        \"dropout_factor\": 1.0,\n",
    "        \"freeze_layers\": [],\n",
    "        \"augmentation_strength\": \"medium\",\n",
    "        \"add_batch_norm\": True,\n",
    "        \"increase_attention_heads\": True\n",
    "    }\n",
    "}\n",
    "\n",
    "config = FINE_TUNING_CONFIG[FINE_TUNING_STRATEGY]\n",
    "print(f\"Selected Strategy: {config['name']}\")\n",
    "print(f\"Description: {config['description']}\")\n",
    "print(f\"Epochs: {config['epochs']}, Learning Rate: {config['learning_rate']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0748aaf7",
   "metadata": {},
   "source": [
    "## 3. Load Data with Enhanced Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46891b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data loading modules\n",
    "from src.data.dataset import create_multimodal_dataloaders\n",
    "from torchvision import transforms\n",
    "\n",
    "def get_augmentation_transforms(strength=\"medium\"):\n",
    "    \"\"\"Get data augmentation transforms based on strength level\"\"\"\n",
    "    \n",
    "    if strength == \"light\":\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.RandomHorizontalFlip(p=0.3),\n",
    "            transforms.RandomRotation(5),\n",
    "            transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    \n",
    "    elif strength == \"medium\":\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.RandomRotation(10),\n",
    "            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.1),\n",
    "            transforms.RandomAffine(degrees=0, translate=(0.05, 0.05)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    \n",
    "    else:  # strong\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.RandomVerticalFlip(p=0.3),\n",
    "            transforms.RandomRotation(15),\n",
    "            transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.2, hue=0.1),\n",
    "            transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "# Load data with enhanced augmentation\n",
    "data_dir = project_root / 'data'\n",
    "dataset_path = data_dir / 'train'\n",
    "\n",
    "print(f\"Loading data with {config['augmentation_strength']} augmentation...\")\n",
    "\n",
    "train_loader, val_loader, test_loader, vocab_size, num_classes, vocab, answer_to_idx = create_multimodal_dataloaders(\n",
    "    train_csv=str(data_dir / 'trainrenamed.csv'),\n",
    "    test_csv=str(data_dir / 'testrenamed.csv'),\n",
    "    image_dir=str(dataset_path),\n",
    "    answers_file=str(data_dir / 'answers.txt'),\n",
    "    batch_size=config['batch_size'],\n",
    "    val_split=0.1,\n",
    "    num_workers=0,\n",
    "    image_size=224,\n",
    "    train_transform=get_augmentation_transforms(config['augmentation_strength'])\n",
    ")\n",
    "\n",
    "print(f\"Data loaded: {len(train_loader)} train, {len(val_loader)} val, {len(test_loader)} test batches\")\n",
    "print(f\"Vocabulary size: {vocab_size}, Classes: {num_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f030b7ca",
   "metadata": {},
   "source": [
    "## 4. Load Best Model and Create Fine-tuned Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c89d0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import model classes\n",
    "from improved_multimodal_model import ImprovedMultimodalVQA\n",
    "\n",
    "def create_fine_tuned_model(base_model, config):\n",
    "    \"\"\"Create a fine-tuned version of the model with optional architectural tweaks\"\"\"\n",
    "    \n",
    "    if config.get('add_batch_norm', False):\n",
    "        # Add batch normalization layers\n",
    "        print(\"Adding batch normalization to classifier\")\n",
    "        base_model.classifier = nn.Sequential(\n",
    "            nn.Linear(base_model.classifier[0].in_features, base_model.classifier[0].out_features),\n",
    "            nn.BatchNorm1d(base_model.classifier[0].out_features),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(base_model.classifier[2].p * config.get('dropout_factor', 1.0)),\n",
    "            nn.Linear(base_model.classifier[4].in_features, base_model.classifier[4].out_features)\n",
    "        )\n",
    "    \n",
    "    if config.get('increase_attention_heads', False):\n",
    "        # Increase attention heads if possible\n",
    "        print(\"Increasing attention heads to 16\")\n",
    "        base_model.cross_attention = nn.MultiheadAttention(\n",
    "            embed_dim=512, \n",
    "            num_heads=16,  # Increased from 8\n",
    "            dropout=0.3 * config.get('dropout_factor', 1.0)\n",
    "        )\n",
    "    \n",
    "    # Adjust dropout in other layers if needed\n",
    "    if config.get('dropout_factor', 1.0) != 1.0:\n",
    "        factor = config['dropout_factor']\n",
    "        base_model.text_dropout.p = min(0.5, base_model.text_dropout.p * factor)\n",
    "        \n",
    "        # Update classifier dropout if not already modified\n",
    "        if not config.get('add_batch_norm', False):\n",
    "            base_model.classifier[2].p = min(0.7, base_model.classifier[2].p * factor)\n",
    "    \n",
    "    return base_model\n",
    "\n",
    "# Load the best checkpoint\n",
    "checkpoint_dir = project_root / 'checkpoints' / 'multimodal_concat'\n",
    "checkpoint_path = checkpoint_dir / 'best_model.pth'\n",
    "\n",
    "if checkpoint_path.exists():\n",
    "    print(f\"Loading best model from {checkpoint_path}\")\n",
    "    \n",
    "    # Create base model\n",
    "    model = ImprovedMultimodalVQA(\n",
    "        vocab_size=vocab_size,\n",
    "        num_classes=num_classes,\n",
    "        embedding_dim=300,\n",
    "        text_hidden_dim=512,\n",
    "        fusion_hidden_dim=512,\n",
    "        dropout=0.3\n",
    "    )\n",
    "    \n",
    "    # Load checkpoint\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    # Apply fine-tuning modifications\n",
    "    model = create_fine_tuned_model(model, config)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    print(f\"Model loaded successfully!\")\n",
    "    print(f\"Original best validation accuracy from checkpoint: {checkpoint.get('best_val_acc', 'N/A')}\")\n",
    "    \n",
    "    # Print model info\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"Total parameters: {total_params:,}\")\n",
    "    print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "    \n",
    "else:\n",
    "    raise FileNotFoundError(f\"Best model checkpoint not found at {checkpoint_path}\")\n",
    "    print(\"Please run the main training notebook first to create the best model checkpoint.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420b9548",
   "metadata": {},
   "source": [
    "## 5. Setup Fine-tuning Optimizer and Training Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be510bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_fine_tuning_optimizer(model, config):\n",
    "    \"\"\"Setup optimizer with strategy-specific parameters\"\"\"\n",
    "    \n",
    "    # Categorize parameters\n",
    "    vision_params = []\n",
    "    text_params = []\n",
    "    fusion_params = []\n",
    "    \n",
    "    for name, param in model.named_parameters():\n",
    "        if any(x in name for x in ['vision_encoder', 'spatial_attention', 'vision_proj']):\n",
    "            vision_params.append(param)\n",
    "        elif any(x in name for x in ['text_embedding', 'text_lstm', 'text_proj', 'text_dropout']):\n",
    "            text_params.append(param)\n",
    "        else:\n",
    "            fusion_params.append(param)\n",
    "    \n",
    "    print(f\"Vision parameters: {len(vision_params)}\")\n",
    "    print(f\"Text parameters: {len(text_params)}\")\n",
    "    print(f\"Fusion parameters: {len(fusion_params)}\")\n",
    "    \n",
    "    # Setup parameter groups based on strategy\n",
    "    if FINE_TUNING_STRATEGY == \"layerwise\":\n",
    "        param_groups = [\n",
    "            {'params': vision_params, 'lr': config['learning_rate'] * config['vision_lr_factor'], 'name': 'vision'},\n",
    "            {'params': text_params, 'lr': config['learning_rate'] * config.get('text_lr_factor', 0.3), 'name': 'text'},\n",
    "            {'params': fusion_params, 'lr': config['learning_rate'] * config.get('fusion_lr_factor', 1.0), 'name': 'fusion'}\n",
    "        ]\n",
    "        print(f\"Layer-wise LR: vision={param_groups[0]['lr']:.2e}, text={param_groups[1]['lr']:.2e}, fusion={param_groups[2]['lr']:.2e}\")\n",
    "    else:\n",
    "        param_groups = [\n",
    "            {'params': vision_params, 'lr': config['learning_rate'] * config['vision_lr_factor'], 'name': 'vision'},\n",
    "            {'params': text_params + fusion_params, 'lr': config['learning_rate'], 'name': 'other'}\n",
    "        ]\n",
    "        print(f\"Standard LR: vision={param_groups[0]['lr']:.2e}, other={param_groups[1]['lr']:.2e}\")\n",
    "    \n",
    "    optimizer = optim.AdamW(param_groups, weight_decay=config['weight_decay'])\n",
    "    \n",
    "    return optimizer\n",
    "\n",
    "def apply_layer_freezing(model, freeze_layers):\n",
    "    \"\"\"Freeze specified layers\"\"\"\n",
    "    for layer_name in freeze_layers:\n",
    "        for name, param in model.named_parameters():\n",
    "            if layer_name in name:\n",
    "                param.requires_grad = False\n",
    "                print(f\"Frozen: {name}\")\n",
    "\n",
    "# Setup optimizer\n",
    "optimizer = setup_fine_tuning_optimizer(model, config)\n",
    "\n",
    "# Apply initial layer freezing if specified\n",
    "if config.get('freeze_layers', []):\n",
    "    apply_layer_freezing(model, config['freeze_layers'])\n",
    "\n",
    "# Setup loss function with label smoothing\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=config['label_smoothing'])\n",
    "print(f\"Using label smoothing: {config['label_smoothing']}\")\n",
    "\n",
    "# Setup scheduler\n",
    "if FINE_TUNING_STRATEGY == \"progressive\":\n",
    "    scheduler = optim.lr_scheduler.LinearLR(optimizer, start_factor=0.5, total_iters=config['epochs']//2)\n",
    "else:\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "        optimizer, T_0=max(2, config['epochs']//3), T_mult=2, eta_min=1e-7\n",
    "    )\n",
    "\n",
    "print(f\"Setup complete for {config['name']} strategy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a77a4c",
   "metadata": {},
   "source": [
    "## 6. Fine-tuning Training Loop with Advanced Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a108f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine_tune_epoch(model, train_loader, val_loader, optimizer, criterion, scheduler, device, epoch, config):\n",
    "    \"\"\"Enhanced training epoch with fine-tuning considerations\"\"\"\n",
    "    \n",
    "    # Progressive unfreezing logic\n",
    "    if FINE_TUNING_STRATEGY == \"progressive\" and 'freeze_schedule' in config:\n",
    "        freeze_schedule = config['freeze_schedule']\n",
    "        if epoch in freeze_schedule:\n",
    "            # Unfreeze specified layers\n",
    "            for name, param in model.named_parameters():\n",
    "                if any(layer in name for layer in freeze_schedule[epoch]):\n",
    "                    param.requires_grad = True\n",
    "                    print(f\"Unfrozen at epoch {epoch}: {name}\")\n",
    "    \n",
    "    # Training phase\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    \n",
    "    print(f\"Fine-tuning Epoch {epoch}/{config['epochs']}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    pbar = tqdm(train_loader, desc=f\"Training\")\n",
    "    \n",
    "    for batch_idx, (questions, images, answers) in enumerate(pbar):\n",
    "        questions, images, answers = questions.to(device), images.to(device), answers.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(questions, images)\n",
    "        loss = criterion(outputs, answers)\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gentle gradient clipping for fine-tuning\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        # Track metrics\n",
    "        train_losses.append(loss.item())\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        train_total += answers.size(0)\n",
    "        train_correct += (predicted == answers).sum().item()\n",
    "        \n",
    "        # Update progress bar\n",
    "        current_acc = 100. * train_correct / train_total\n",
    "        pbar.set_postfix({'loss': f'{loss.item():.4f}', 'acc': f'{current_acc:.2f}%'})\n",
    "    \n",
    "    # Calculate epoch averages\n",
    "    avg_train_loss = sum(train_losses) / len(train_losses)\n",
    "    train_accuracy = 100. * train_correct / train_total\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_losses = []\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pbar_val = tqdm(val_loader, desc=\"Validating\")\n",
    "        for questions, images, answers in pbar_val:\n",
    "            questions, images, answers = questions.to(device), images.to(device), answers.to(device)\n",
    "            outputs = model(questions, images)\n",
    "            loss = criterion(outputs, answers)\n",
    "            \n",
    "            val_losses.append(loss.item())\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            val_total += answers.size(0)\n",
    "            val_correct += (predicted == answers).sum().item()\n",
    "    \n",
    "    avg_val_loss = sum(val_losses) / len(val_losses)\n",
    "    val_accuracy = 100. * val_correct / val_total\n",
    "    \n",
    "    # Update scheduler\n",
    "    scheduler.step()\n",
    "    \n",
    "    # Print epoch summary\n",
    "    print(f\"\\nEpoch {epoch} Results:\")\n",
    "    print(f\"Train Loss: {avg_train_loss:.4f} | Train Acc: {train_accuracy:.2f}%\")\n",
    "    print(f\"Val Loss:   {avg_val_loss:.4f} | Val Acc:   {val_accuracy:.2f}%\")\n",
    "    print(f\"Learning Rate: Vision={optimizer.param_groups[0]['lr']:.2e}, Other={optimizer.param_groups[-1]['lr']:.2e}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    return {\n",
    "        'train_loss': avg_train_loss,\n",
    "        'train_accuracy': train_accuracy,\n",
    "        'val_loss': avg_val_loss,\n",
    "        'val_accuracy': val_accuracy\n",
    "    }\n",
    "\n",
    "print(\"Fine-tuning training function ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986aae86",
   "metadata": {},
   "source": [
    "## 7. Execute Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5c7b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tuning execution\n",
    "print(f\"Starting {config['name']}...\")\n",
    "print(f\"Strategy: {config['description']}\")\n",
    "print(f\"Epochs: {config['epochs']}, Batch Size: {config['batch_size']}\")\n",
    "\n",
    "# Initialize tracking\n",
    "fine_tune_history = {\n",
    "    'train_losses': [],\n",
    "    'train_accuracies': [],\n",
    "    'val_losses': [],\n",
    "    'val_accuracies': []\n",
    "}\n",
    "\n",
    "# Get baseline performance (original best model performance)\n",
    "original_best_acc = checkpoint.get('best_val_acc', 55.39)  # Default to known best\n",
    "print(f\"Target: Improve upon {original_best_acc:.2f}% validation accuracy\")\n",
    "\n",
    "best_fine_tune_acc = 0.0\n",
    "best_model_state = None\n",
    "start_time = time.time()\n",
    "\n",
    "try:\n",
    "    for epoch in range(1, config['epochs'] + 1):\n",
    "        # Fine-tune one epoch\n",
    "        epoch_results = fine_tune_epoch(\n",
    "            model, train_loader, val_loader,\n",
    "            optimizer, criterion, scheduler,\n",
    "            device, epoch, config\n",
    "        )\n",
    "        \n",
    "        # Store history\n",
    "        fine_tune_history['train_losses'].append(epoch_results['train_loss'])\n",
    "        fine_tune_history['train_accuracies'].append(epoch_results['train_accuracy'])\n",
    "        fine_tune_history['val_losses'].append(epoch_results['val_loss'])\n",
    "        fine_tune_history['val_accuracies'].append(epoch_results['val_accuracy'])\n",
    "        \n",
    "        # Check for improvement\n",
    "        current_val_acc = epoch_results['val_accuracy']\n",
    "        if current_val_acc > best_fine_tune_acc:\n",
    "            best_fine_tune_acc = current_val_acc\n",
    "            best_model_state = model.state_dict().copy()\n",
    "            improvement_vs_original = current_val_acc - original_best_acc\n",
    "            print(f\"New best fine-tuned accuracy: {current_val_acc:.2f}%\")\n",
    "            if improvement_vs_original > 0:\n",
    "                print(f\"Improvement over original: +{improvement_vs_original:.2f} pp\")\n",
    "            \n",
    "            # Save fine-tuned checkpoint\n",
    "            ft_checkpoint_dir = project_root / 'checkpoints' / f'fine_tuned_{FINE_TUNING_STRATEGY}'\n",
    "            ft_checkpoint_dir.mkdir(exist_ok=True)\n",
    "            ft_checkpoint_path = ft_checkpoint_dir / 'best_model.pth'\n",
    "            \n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': best_model_state,\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'best_val_acc': best_fine_tune_acc,\n",
    "                'original_acc': original_best_acc,\n",
    "                'fine_tune_history': fine_tune_history,\n",
    "                'config': config,\n",
    "                'strategy': FINE_TUNING_STRATEGY\n",
    "            }, ft_checkpoint_path)\n",
    "        \n",
    "        # Early stopping check (very patient for fine-tuning)\n",
    "        if epoch >= 5:  # Minimum epochs\n",
    "            recent_accs = fine_tune_history['val_accuracies'][-3:]\n",
    "            if len(recent_accs) >= 3 and all(acc < max(fine_tune_history['val_accuracies']) - 1.0 for acc in recent_accs):\n",
    "                print(f\"Early stopping triggered - no improvement for 3 epochs\")\n",
    "                break\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nFine-tuning interrupted by user\")\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(f\"\\nFine-tuning completed in {training_time/60:.2f} minutes\")\n",
    "print(f\"Best fine-tuned validation accuracy: {best_fine_tune_acc:.2f}%\")\n",
    "print(f\"Original best accuracy: {original_best_acc:.2f}%\")\n",
    "improvement = best_fine_tune_acc - original_best_acc\n",
    "print(f\"Overall improvement: {improvement:+.2f} percentage points\")\n",
    "\n",
    "# Load best fine-tuned model\n",
    "if best_model_state is not None:\n",
    "    model.load_state_dict(best_model_state)\n",
    "    print(\"Best fine-tuned model loaded for evaluation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3158d1",
   "metadata": {},
   "source": [
    "## 8. Comprehensive Evaluation and Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259e65f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive evaluation function\n",
    "def evaluate_fine_tuned_model(model, test_loader, device, strategy_name):\n",
    "    \"\"\"Comprehensive evaluation of fine-tuned model\"\"\"\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    test_loss = 0.0\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    print(f\"Evaluating {strategy_name} fine-tuned model on test set...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(test_loader, desc=\"Testing\")\n",
    "        for questions, images, answers in pbar:\n",
    "            questions, images, answers = questions.to(device), images.to(device), answers.to(device)\n",
    "            \n",
    "            outputs = model(questions, images)\n",
    "            loss = criterion(outputs, answers)\n",
    "            test_loss += loss.item()\n",
    "            \n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_targets.extend(answers.cpu().numpy())\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(all_targets, all_predictions)\n",
    "    avg_loss = test_loss / len(test_loader)\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'avg_loss': avg_loss,\n",
    "        'predictions': all_predictions,\n",
    "        'targets': all_targets\n",
    "    }\n",
    "\n",
    "# Evaluate fine-tuned model\n",
    "ft_results = evaluate_fine_tuned_model(model, test_loader, device, config['name'])\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(f\"FINE-TUNING RESULTS - {config['name'].upper()}\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Test Accuracy: {ft_results['accuracy']:.4f} ({ft_results['accuracy']*100:.2f}%)\")\n",
    "print(f\"Test Loss: {ft_results['avg_loss']:.4f}\")\n",
    "\n",
    "# Load original results for comparison\n",
    "baseline_results_path = project_root / 'results' / 'text_baseline_results.json'\n",
    "original_multimodal_path = project_root / 'results' / 'improved_multimodal_results.json'\n",
    "\n",
    "print(\"\\nPerformance Comparison:\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "if baseline_results_path.exists():\n",
    "    with open(baseline_results_path, 'r') as f:\n",
    "        baseline_results = json.load(f)\n",
    "    baseline_acc = baseline_results['accuracy']\n",
    "    print(f\"Text Baseline:        {baseline_acc:.4f} ({baseline_acc*100:.2f}%)\")\n",
    "    \n",
    "    improvement_vs_baseline = (ft_results['accuracy'] - baseline_acc) * 100\n",
    "    print(f\"vs Text Baseline:     {improvement_vs_baseline:+.2f} pp\")\n",
    "\n",
    "if original_multimodal_path.exists():\n",
    "    with open(original_multimodal_path, 'r') as f:\n",
    "        original_results = json.load(f)\n",
    "    original_acc = original_results['test_metrics']['accuracy']\n",
    "    print(f\"Original Multimodal:  {original_acc:.4f} ({original_acc*100:.2f}%)\")\n",
    "    \n",
    "    improvement_vs_original = (ft_results['accuracy'] - original_acc) * 100\n",
    "    print(f\"vs Original:          {improvement_vs_original:+.2f} pp\")\n",
    "\n",
    "print(f\"Fine-tuned Model:     {ft_results['accuracy']:.4f} ({ft_results['accuracy']*100:.2f}%)\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ca9f51",
   "metadata": {},
   "source": [
    "## 9. Visualization and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730fad22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training history visualization\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "epochs_range = range(1, len(fine_tune_history['train_losses']) + 1)\n",
    "\n",
    "# Loss curves\n",
    "ax1.plot(epochs_range, fine_tune_history['train_losses'], 'b-', label='Training Loss', linewidth=2)\n",
    "ax1.plot(epochs_range, fine_tune_history['val_losses'], 'r-', label='Validation Loss', linewidth=2)\n",
    "ax1.set_title(f'Fine-tuning Loss Curves - {config[\"name\"]}', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy curves\n",
    "ax2.plot(epochs_range, fine_tune_history['train_accuracies'], 'b-', label='Training Accuracy', linewidth=2)\n",
    "ax2.plot(epochs_range, fine_tune_history['val_accuracies'], 'r-', label='Validation Accuracy', linewidth=2)\n",
    "ax2.axhline(y=original_best_acc, color='g', linestyle='--', alpha=0.7, label=f'Original Best ({original_best_acc:.1f}%)')\n",
    "ax2.set_title('Fine-tuning Accuracy Curves', fontsize=14, fontweight='bold')\n",
    "ax2.set_xlabel('Epochs')\n",
    "ax2.set_ylabel('Accuracy (%)')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Performance comparison bar chart\n",
    "models = ['Text Baseline', 'Original Multimodal', f'Fine-tuned\\n({FINE_TUNING_STRATEGY})']\n",
    "accuracies = []\n",
    "\n",
    "if baseline_results_path.exists():\n",
    "    accuracies.append(baseline_acc * 100)\n",
    "else:\n",
    "    accuracies.append(47.36)  # Known baseline\n",
    "\n",
    "if original_multimodal_path.exists():\n",
    "    accuracies.append(original_acc * 100)\n",
    "else:\n",
    "    accuracies.append(55.39)  # Known best\n",
    "\n",
    "accuracies.append(ft_results['accuracy'] * 100)\n",
    "\n",
    "bars = ax3.bar(models, accuracies, color=['skyblue', 'lightgreen', 'lightcoral'], alpha=0.8)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, acc in zip(bars, accuracies):\n",
    "    height = bar.get_height()\n",
    "    ax3.text(bar.get_x() + bar.get_width()/2., height + 0.3,\n",
    "            f'{acc:.2f}%', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "ax3.set_title('Model Performance Comparison', fontsize=14, fontweight='bold')\n",
    "ax3.set_ylabel('Accuracy (%)')\n",
    "ax3.set_ylim(0, max(accuracies) + 5)\n",
    "ax3.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Fine-tuning strategy summary\n",
    "ax4.axis('off')\n",
    "summary_text = f\"\"\"\n",
    "Fine-tuning Strategy: {config['name']}\n",
    "\n",
    "Configuration:\n",
    "• Learning Rate: {config['learning_rate']:.2e}\n",
    "• Vision LR Factor: {config['vision_lr_factor']}\n",
    "• Epochs: {config['epochs']}\n",
    "• Label Smoothing: {config['label_smoothing']}\n",
    "• Augmentation: {config['augmentation_strength']}\n",
    "\n",
    "Results:\n",
    "• Best Val Acc: {best_fine_tune_acc:.2f}%\n",
    "• Test Accuracy: {ft_results['accuracy']*100:.2f}%\n",
    "• Improvement: {improvement:+.2f} pp\n",
    "• Training Time: {training_time/60:.1f} min\n",
    "\"\"\"\n",
    "\n",
    "ax4.text(0.05, 0.95, summary_text, fontsize=11, verticalalignment='top',\n",
    "         bbox=dict(boxstyle=\"round,pad=0.5\", facecolor=\"lightblue\", alpha=0.7))\n",
    "ax4.set_title('Fine-tuning Summary', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save visualization\n",
    "results_dir = project_root / 'results' / 'figures'\n",
    "results_dir.mkdir(exist_ok=True, parents=True)\n",
    "fig.savefig(results_dir / f'fine_tuning_{FINE_TUNING_STRATEGY}_results.png', dpi=300, bbox_inches='tight')\n",
    "print(f\"\\nVisualization saved to: {results_dir / f'fine_tuning_{FINE_TUNING_STRATEGY}_results.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067d3f4b",
   "metadata": {},
   "source": [
    "## 10. Save Fine-tuning Results and Generate Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfdd990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save comprehensive fine-tuning results\n",
    "results_dir = project_root / 'results'\n",
    "results_dir.mkdir(exist_ok=True)\n",
    "\n",
    "fine_tuning_results = {\n",
    "    'strategy': FINE_TUNING_STRATEGY,\n",
    "    'strategy_name': config['name'],\n",
    "    'strategy_description': config['description'],\n",
    "    'configuration': config,\n",
    "    'training_history': fine_tune_history,\n",
    "    'results': {\n",
    "        'best_validation_accuracy': best_fine_tune_acc / 100,\n",
    "        'test_accuracy': ft_results['accuracy'],\n",
    "        'test_loss': ft_results['avg_loss'],\n",
    "        'training_time_minutes': training_time / 60,\n",
    "        'total_epochs': len(fine_tune_history['train_losses'])\n",
    "    },\n",
    "    'improvements': {\n",
    "        'vs_original_multimodal': improvement,\n",
    "        'vs_text_baseline': improvement_vs_baseline if 'improvement_vs_baseline' in locals() else None\n",
    "    },\n",
    "    'model_info': {\n",
    "        'total_parameters': total_params,\n",
    "        'trainable_parameters': trainable_params\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save results\n",
    "results_file = results_dir / f'fine_tuning_{FINE_TUNING_STRATEGY}_results.json'\n",
    "with open(results_file, 'w') as f:\n",
    "    json.dump(fine_tuning_results, f, indent=2)\n",
    "\n",
    "print(f\"Fine-tuning results saved to: {results_file}\")\n",
    "\n",
    "# Generate confusion matrix if we have good performance\n",
    "if ft_results['accuracy'] > 0.5:  # Only if accuracy is decent\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    # Use a subset of classes for cleaner visualization\n",
    "    unique_targets = sorted(set(ft_results['targets']))\n",
    "    if len(unique_targets) > 20:  # Too many classes for clean visualization\n",
    "        # Show top 20 most common classes\n",
    "        from collections import Counter\n",
    "        target_counts = Counter(ft_results['targets'])\n",
    "        top_classes = [cls for cls, _ in target_counts.most_common(20)]\n",
    "        \n",
    "        # Filter data for top classes only\n",
    "        filtered_targets = []\n",
    "        filtered_preds = []\n",
    "        for i, target in enumerate(ft_results['targets']):\n",
    "            if target in top_classes:\n",
    "                filtered_targets.append(target)\n",
    "                filtered_preds.append(ft_results['predictions'][i])\n",
    "        \n",
    "        cm = confusion_matrix(filtered_targets, filtered_preds, labels=top_classes)\n",
    "        title_suffix = \" (Top 20 Classes)\"\n",
    "    else:\n",
    "        cm = confusion_matrix(ft_results['targets'], ft_results['predictions'])\n",
    "        title_suffix = \"\"\n",
    "    \n",
    "    sns.heatmap(cm, annot=False, fmt='d', cmap='Blues', cbar=True)\n",
    "    plt.title(f'Fine-tuned Model Confusion Matrix{title_suffix}\\n{config[\"name\"]}')\n",
    "    plt.xlabel('Predicted Class')\n",
    "    plt.ylabel('True Class')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save confusion matrix\n",
    "    cm_path = results_dir / 'figures' / f'fine_tuned_{FINE_TUNING_STRATEGY}_confusion_matrix.png'\n",
    "    plt.savefig(cm_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(f\"Confusion matrix saved to: {cm_path}\")\n",
    "\n",
    "# Print final summary\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(f\"FINE-TUNING COMPLETED: {config['name'].upper()}\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Strategy Description: {config['description']}\")\n",
    "print(f\"Training Time: {training_time/60:.2f} minutes\")\n",
    "print(f\"Best Validation Accuracy: {best_fine_tune_acc:.2f}%\")\n",
    "print(f\"Test Accuracy: {ft_results['accuracy']*100:.2f}%\")\n",
    "print(f\"Improvement over Original: {improvement:+.2f} percentage points\")\n",
    "\n",
    "if improvement > 0:\n",
    "    print(\"\\nCONGRATULATIONS! Fine-tuning was successful!\")\n",
    "    print(f\"Your model has improved by {improvement:.2f} percentage points.\")\n",
    "else:\n",
    "    print(\"\\nFine-tuning did not improve performance.\")\n",
    "    print(\"Consider trying a different strategy or adjusting hyperparameters.\")\n",
    "\n",
    "print(f\"\\nAll results and checkpoints saved in:\")\n",
    "print(f\"- Results: {results_file}\")\n",
    "print(f\"- Checkpoint: {ft_checkpoint_path}\")\n",
    "print(f\"- Visualizations: {results_dir / 'figures'}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1f7a37",
   "metadata": {},
   "source": [
    "## 11. Strategy Comparison and Recommendations\n",
    "\n",
    "**Available Fine-tuning Strategies:**\n",
    "\n",
    "1. **Conservative:** Safe, minimal changes with very low learning rates\n",
    "2. **Layerwise:** Different learning rates for different model components  \n",
    "3. **Progressive:** Gradually unfreeze layers during training\n",
    "4. **Augmented:** Enhanced data augmentation for better generalization\n",
    "5. **Regularization:** Optimize dropout and weight decay parameters\n",
    "6. **Architecture:** Minor architectural modifications\n",
    "\n",
    "**To try different strategies:**\n",
    "1. Change `FINE_TUNING_STRATEGY` at the top of this notebook\n",
    "2. Re-run cells 2 onwards\n",
    "3. Compare results across strategies\n",
    "\n",
    "**Next Steps:**\n",
    "- Try multiple strategies and compare results\n",
    "- Ensemble the best fine-tuned models\n",
    "- Use the best model for inference applications"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
